{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunne parameters of the selected model from the previous spot-checks\n",
    "In this script we spot-check different EEG classification models to clasify different epochs of one subject into resting state, left hand movement and right hand movement using leave one subject out cross-validation, with the model  selected from the previously done spot-check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of some models to evaluate them {key:model name} {values:model object}\n",
    "def define_models_svcl(models=dict()) :\n",
    "    C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    cont = 1\n",
    "    for C_val in C_values :\n",
    "        models['svm%d' % (cont)] = SVC(kernel='linear', C=C_val, probability=True)\n",
    "        cont = cont + 1\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict of some models to evaluate them {key:model name} {values:model object}\n",
    "def define_models_logistic(models=dict()) :\n",
    "    C_values = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    cont1 = 1\n",
    "    for C_val in C_values :\n",
    "        models['logistic%d' % (cont1)] = LogisticRegression(C=C_val)\n",
    "        cont1 = cont1 + 1\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a single model\n",
    "def evaluate_model(X, y, model, subjects_train):\n",
    "    # evaluate model\n",
    "    scores = dict()\n",
    "    scores['accuracy'] = []\n",
    "    scores['roc_auc'] = []\n",
    "    scores['f1'] = []\n",
    "    for subject in subjects_train :\n",
    "        train_idx = subjects_idx_train != subject\n",
    "        X_training = X[train_idx.values]\n",
    "        y_training = y[train_idx.values]\n",
    "        val_idx = subjects_idx_train == subject\n",
    "        X_val = X[val_idx.values]\n",
    "        y_val = y[val_idx.values]\n",
    "        #train the model\n",
    "        model.fit(X_training,y_training)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_prob = model.predict_proba(X_val)\n",
    "        scores['accuracy'].append(accuracy_score(y_val,y_pred))\n",
    "        scores['roc_auc'].append(roc_auc_score(y_val,y_prob,multi_class='ovo',labels=[0,1,2]))\n",
    "        scores['f1'].append(f1_score(y_val,y_pred,average='weighted'))\n",
    "        print(subject)\n",
    "    print(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a dict of models {name:object}, returns {name:score}\n",
    "def evaluate_models(X, y, models, subjects_train):\n",
    "    results = dict()\n",
    "    metric='accuracy'\n",
    "    for name, model in models.items():\n",
    "        scores = evaluate_model(X, y, model, subjects_train)\n",
    "        results[name] = scores\n",
    "        print(name,'evaluated')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print and plot the results of the models in order (from the best one to the worse one)\n",
    "def summarize_results(results):\n",
    "    # create a list of (name, mean(scores)) tuples\n",
    "    mean_accuracy_scores = dict()\n",
    "    mean_auc_scores = dict()\n",
    "    mean_f1_scores = dict()\n",
    "    for k,v in results.items() :\n",
    "        mean_accuracy_scores.update({k : mean(v['accuracy'])})\n",
    "        mean_auc_scores.update({k : mean(v['roc_auc'])})\n",
    "        mean_f1_scores.update({k : mean(v['f1'])})\n",
    "    # sort tuples by mean score\n",
    "    ordered_accuracy = sorted(mean_accuracy_scores.items(), key=lambda x: x[1])\n",
    "    # reverse for descending order (from the best one to the worse one)\n",
    "    ordered_accuracy = list(reversed(ordered_accuracy))\n",
    "    # retrieve the top for summarization\n",
    "    names = [x[0] for x in ordered_accuracy]\n",
    "    accuracy_scores = [results[x]['accuracy'] for x in names]\n",
    "    auc_scores = [results[x]['roc_auc'] for x in names]\n",
    "    f1_scores = [results[x]['f1'] for x in names]\n",
    "    # print the top \n",
    "    print()\n",
    "    for i in range(len(results)):\n",
    "        name = names[i]\n",
    "        mean_accuracy_score = mean_accuracy_scores[name]\n",
    "        mean_auc_score = mean_auc_scores[name]\n",
    "        mean_f1 = mean_f1_scores[name]\n",
    "        print('Rank=%d, Name=%s, Accuracy=%.3f, roc_auc=%.3f, f1=%.3f' % (i+1, name, mean_accuracy_score, mean_auc_score, mean_f1))\n",
    "    # boxplot for the top n\n",
    "    print(mean_accuracy_score, names)\n",
    "    plt.figure()\n",
    "    plt.boxplot(accuracy_scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    plt.title('Accuracy scores')\n",
    "    plt.figure()\n",
    "    plt.boxplot(auc_scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    plt.title('ROC-AUC scores')\n",
    "    plt.figure()\n",
    "    plt.boxplot(f1_scores, labels=names)\n",
    "    _, labels = pyplot.xticks()\n",
    "    pyplot.setp(labels, rotation=90)\n",
    "    plt.title('F1 scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read statistical features and labels from all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Mean_FC5</th>\n",
       "      <th>Variance_FC5</th>\n",
       "      <th>Kurtosis_FC5</th>\n",
       "      <th>Mean_FC3</th>\n",
       "      <th>Variance_FC3</th>\n",
       "      <th>Kurtosis_FC3</th>\n",
       "      <th>Mean_FC1</th>\n",
       "      <th>Variance_FC1</th>\n",
       "      <th>...</th>\n",
       "      <th>PLV_CP1_CP2</th>\n",
       "      <th>PLV_CP1_CP4</th>\n",
       "      <th>PLV_CP1_CP6</th>\n",
       "      <th>PLV_CPz_CP2</th>\n",
       "      <th>PLV_CPz_CP4</th>\n",
       "      <th>PLV_CPz_CP6</th>\n",
       "      <th>PLV_CP2_CP4</th>\n",
       "      <th>PLV_CP2_CP6</th>\n",
       "      <th>PLV_CP4_CP6</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077105</td>\n",
       "      <td>7.357580</td>\n",
       "      <td>2.809176</td>\n",
       "      <td>0.382332</td>\n",
       "      <td>7.589385</td>\n",
       "      <td>3.297552</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>7.700149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318132</td>\n",
       "      <td>0.073507</td>\n",
       "      <td>0.323108</td>\n",
       "      <td>0.669452</td>\n",
       "      <td>0.247354</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.685624</td>\n",
       "      <td>0.365035</td>\n",
       "      <td>0.772310</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.018304</td>\n",
       "      <td>7.029542</td>\n",
       "      <td>2.842915</td>\n",
       "      <td>0.184697</td>\n",
       "      <td>6.991603</td>\n",
       "      <td>3.060431</td>\n",
       "      <td>0.281971</td>\n",
       "      <td>7.484742</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470648</td>\n",
       "      <td>0.123157</td>\n",
       "      <td>0.181453</td>\n",
       "      <td>0.699222</td>\n",
       "      <td>0.302571</td>\n",
       "      <td>0.062673</td>\n",
       "      <td>0.705291</td>\n",
       "      <td>0.361569</td>\n",
       "      <td>0.726673</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.319861</td>\n",
       "      <td>6.399684</td>\n",
       "      <td>3.428581</td>\n",
       "      <td>-0.346442</td>\n",
       "      <td>6.964995</td>\n",
       "      <td>2.777844</td>\n",
       "      <td>-0.256384</td>\n",
       "      <td>8.132662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580862</td>\n",
       "      <td>0.386278</td>\n",
       "      <td>0.231118</td>\n",
       "      <td>0.773177</td>\n",
       "      <td>0.498727</td>\n",
       "      <td>0.242550</td>\n",
       "      <td>0.764621</td>\n",
       "      <td>0.475057</td>\n",
       "      <td>0.770152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.036567</td>\n",
       "      <td>8.415375</td>\n",
       "      <td>2.555121</td>\n",
       "      <td>0.150948</td>\n",
       "      <td>9.348971</td>\n",
       "      <td>3.053070</td>\n",
       "      <td>0.207301</td>\n",
       "      <td>8.933164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607181</td>\n",
       "      <td>0.256862</td>\n",
       "      <td>0.167798</td>\n",
       "      <td>0.806269</td>\n",
       "      <td>0.438541</td>\n",
       "      <td>0.089317</td>\n",
       "      <td>0.747473</td>\n",
       "      <td>0.330642</td>\n",
       "      <td>0.694656</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.257114</td>\n",
       "      <td>13.767046</td>\n",
       "      <td>2.879540</td>\n",
       "      <td>0.157239</td>\n",
       "      <td>14.221320</td>\n",
       "      <td>2.764797</td>\n",
       "      <td>-0.017693</td>\n",
       "      <td>13.340810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464897</td>\n",
       "      <td>0.257998</td>\n",
       "      <td>0.146752</td>\n",
       "      <td>0.819921</td>\n",
       "      <td>0.607017</td>\n",
       "      <td>0.364591</td>\n",
       "      <td>0.854306</td>\n",
       "      <td>0.557560</td>\n",
       "      <td>0.742894</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>44</td>\n",
       "      <td>256</td>\n",
       "      <td>-0.347318</td>\n",
       "      <td>11.215760</td>\n",
       "      <td>2.415819</td>\n",
       "      <td>-0.551029</td>\n",
       "      <td>13.194753</td>\n",
       "      <td>2.405359</td>\n",
       "      <td>-0.656948</td>\n",
       "      <td>12.642553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080379</td>\n",
       "      <td>0.140109</td>\n",
       "      <td>0.308763</td>\n",
       "      <td>0.595714</td>\n",
       "      <td>0.356431</td>\n",
       "      <td>0.148958</td>\n",
       "      <td>0.845309</td>\n",
       "      <td>0.611503</td>\n",
       "      <td>0.830670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>44</td>\n",
       "      <td>257</td>\n",
       "      <td>0.221785</td>\n",
       "      <td>12.573679</td>\n",
       "      <td>3.445813</td>\n",
       "      <td>0.237528</td>\n",
       "      <td>11.310268</td>\n",
       "      <td>3.638090</td>\n",
       "      <td>0.239306</td>\n",
       "      <td>11.290607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266919</td>\n",
       "      <td>0.165629</td>\n",
       "      <td>0.418936</td>\n",
       "      <td>0.611298</td>\n",
       "      <td>0.252375</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.743924</td>\n",
       "      <td>0.390819</td>\n",
       "      <td>0.758761</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>44</td>\n",
       "      <td>258</td>\n",
       "      <td>-0.429369</td>\n",
       "      <td>7.199075</td>\n",
       "      <td>3.063733</td>\n",
       "      <td>-0.496420</td>\n",
       "      <td>8.957319</td>\n",
       "      <td>3.198463</td>\n",
       "      <td>-0.582399</td>\n",
       "      <td>9.467059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.322126</td>\n",
       "      <td>0.422456</td>\n",
       "      <td>0.720966</td>\n",
       "      <td>0.303902</td>\n",
       "      <td>0.250078</td>\n",
       "      <td>0.694467</td>\n",
       "      <td>0.191094</td>\n",
       "      <td>0.554233</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>44</td>\n",
       "      <td>259</td>\n",
       "      <td>-0.945257</td>\n",
       "      <td>21.763986</td>\n",
       "      <td>6.206397</td>\n",
       "      <td>-0.971078</td>\n",
       "      <td>17.039679</td>\n",
       "      <td>6.818231</td>\n",
       "      <td>-0.958857</td>\n",
       "      <td>15.633321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444469</td>\n",
       "      <td>0.202010</td>\n",
       "      <td>0.083466</td>\n",
       "      <td>0.758260</td>\n",
       "      <td>0.527970</td>\n",
       "      <td>0.244990</td>\n",
       "      <td>0.844094</td>\n",
       "      <td>0.562038</td>\n",
       "      <td>0.789984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>44</td>\n",
       "      <td>260</td>\n",
       "      <td>0.167214</td>\n",
       "      <td>4.859880</td>\n",
       "      <td>3.381623</td>\n",
       "      <td>0.117990</td>\n",
       "      <td>4.956969</td>\n",
       "      <td>2.973658</td>\n",
       "      <td>0.105943</td>\n",
       "      <td>5.630100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533983</td>\n",
       "      <td>0.121270</td>\n",
       "      <td>0.270544</td>\n",
       "      <td>0.764531</td>\n",
       "      <td>0.372002</td>\n",
       "      <td>0.079072</td>\n",
       "      <td>0.688026</td>\n",
       "      <td>0.228740</td>\n",
       "      <td>0.631245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6251 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Epoch  Mean_FC5  Variance_FC5  Kurtosis_FC5  Mean_FC3  \\\n",
       "0          1      1  0.077105      7.357580      2.809176  0.382332   \n",
       "1          1      2 -0.018304      7.029542      2.842915  0.184697   \n",
       "2          1      3 -0.319861      6.399684      3.428581 -0.346442   \n",
       "3          1      4  0.036567      8.415375      2.555121  0.150948   \n",
       "4          1      5  0.257114     13.767046      2.879540  0.157239   \n",
       "..       ...    ...       ...           ...           ...       ...   \n",
       "255       44    256 -0.347318     11.215760      2.415819 -0.551029   \n",
       "256       44    257  0.221785     12.573679      3.445813  0.237528   \n",
       "257       44    258 -0.429369      7.199075      3.063733 -0.496420   \n",
       "258       44    259 -0.945257     21.763986      6.206397 -0.971078   \n",
       "259       44    260  0.167214      4.859880      3.381623  0.117990   \n",
       "\n",
       "     Variance_FC3  Kurtosis_FC3  Mean_FC1  Variance_FC1  ...  PLV_CP1_CP2  \\\n",
       "0        7.589385      3.297552  0.464633      7.700149  ...     0.318132   \n",
       "1        6.991603      3.060431  0.281971      7.484742  ...     0.470648   \n",
       "2        6.964995      2.777844 -0.256384      8.132662  ...     0.580862   \n",
       "3        9.348971      3.053070  0.207301      8.933164  ...     0.607181   \n",
       "4       14.221320      2.764797 -0.017693     13.340810  ...     0.464897   \n",
       "..            ...           ...       ...           ...  ...          ...   \n",
       "255     13.194753      2.405359 -0.656948     12.642553  ...     0.080379   \n",
       "256     11.310268      3.638090  0.239306     11.290607  ...     0.266919   \n",
       "257      8.957319      3.198463 -0.582399      9.467059  ...     0.578182   \n",
       "258     17.039679      6.818231 -0.958857     15.633321  ...     0.444469   \n",
       "259      4.956969      2.973658  0.105943      5.630100  ...     0.533983   \n",
       "\n",
       "     PLV_CP1_CP4  PLV_CP1_CP6  PLV_CPz_CP2  PLV_CPz_CP4  PLV_CPz_CP6  \\\n",
       "0       0.073507     0.323108     0.669452     0.247354     0.067815   \n",
       "1       0.123157     0.181453     0.699222     0.302571     0.062673   \n",
       "2       0.386278     0.231118     0.773177     0.498727     0.242550   \n",
       "3       0.256862     0.167798     0.806269     0.438541     0.089317   \n",
       "4       0.257998     0.146752     0.819921     0.607017     0.364591   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "255     0.140109     0.308763     0.595714     0.356431     0.148958   \n",
       "256     0.165629     0.418936     0.611298     0.252375     0.062959   \n",
       "257     0.322126     0.422456     0.720966     0.303902     0.250078   \n",
       "258     0.202010     0.083466     0.758260     0.527970     0.244990   \n",
       "259     0.121270     0.270544     0.764531     0.372002     0.079072   \n",
       "\n",
       "     PLV_CP2_CP4  PLV_CP2_CP6  PLV_CP4_CP6  Label  \n",
       "0       0.685624     0.365035     0.772310      1  \n",
       "1       0.705291     0.361569     0.726673      2  \n",
       "2       0.764621     0.475057     0.770152      1  \n",
       "3       0.747473     0.330642     0.694656      2  \n",
       "4       0.854306     0.557560     0.742894      2  \n",
       "..           ...          ...          ...    ...  \n",
       "255     0.845309     0.611503     0.830670      0  \n",
       "256     0.743924     0.390819     0.758761      0  \n",
       "257     0.694467     0.191094     0.554233      0  \n",
       "258     0.844094     0.562038     0.789984      0  \n",
       "259     0.688026     0.228740     0.631245      0  \n",
       "\n",
       "[6251 rows x 313 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read subjects files and merge them\n",
    "files = os.listdir('Subjects data')\n",
    "features_all = pd.read_csv('Subjects data/' + files[0], encoding='latin1')\n",
    "files.pop(0)\n",
    "for f in files :\n",
    "    features_subject = pd.read_csv('Subjects data/' + f, encoding='latin1')\n",
    "    frames = [features_all, features_subject]\n",
    "    features_all = pd.concat(frames)\n",
    "#features_all.index = [features_all['Subject'], features_all['Epoch']]\n",
    "subjects_idx = features_all['Subject'].values\n",
    "#features_all = features_all.drop(['Subject','Epoch'], axis = 1)\n",
    "features_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([15, 12, 21, 4, 10, 44, 3, 18, 29, 20, 7, 19, 11, 2, 28, 5, 8, 16, 6],\n",
       " [1, 13, 17, 14, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select randomly subjects for train and test\n",
    "subjects = np.unique(subjects_idx)\n",
    "subjects_train = [15, 12, 21, 4, 10, 44, 3, 18, 29, 20, 7, 19, 11, 2, 28, 5, 8, 16, 6]\n",
    "subjects_test = [1, 13, 17, 14, 9]\n",
    "subjects_train, subjects_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Mean_FC5</th>\n",
       "      <th>Variance_FC5</th>\n",
       "      <th>Kurtosis_FC5</th>\n",
       "      <th>Mean_FC3</th>\n",
       "      <th>Variance_FC3</th>\n",
       "      <th>Kurtosis_FC3</th>\n",
       "      <th>Mean_FC1</th>\n",
       "      <th>Variance_FC1</th>\n",
       "      <th>...</th>\n",
       "      <th>PLV_CP1_CP2</th>\n",
       "      <th>PLV_CP1_CP4</th>\n",
       "      <th>PLV_CP1_CP6</th>\n",
       "      <th>PLV_CPz_CP2</th>\n",
       "      <th>PLV_CPz_CP4</th>\n",
       "      <th>PLV_CPz_CP6</th>\n",
       "      <th>PLV_CP2_CP4</th>\n",
       "      <th>PLV_CP2_CP6</th>\n",
       "      <th>PLV_CP4_CP6</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226124</td>\n",
       "      <td>3.195941</td>\n",
       "      <td>2.881555</td>\n",
       "      <td>-0.275889</td>\n",
       "      <td>2.269788</td>\n",
       "      <td>3.280869</td>\n",
       "      <td>-0.109598</td>\n",
       "      <td>2.684536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.498464</td>\n",
       "      <td>0.109177</td>\n",
       "      <td>0.096379</td>\n",
       "      <td>0.723574</td>\n",
       "      <td>0.384581</td>\n",
       "      <td>0.159108</td>\n",
       "      <td>0.645515</td>\n",
       "      <td>0.389479</td>\n",
       "      <td>0.794813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>0.030149</td>\n",
       "      <td>3.409489</td>\n",
       "      <td>3.228332</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>2.478137</td>\n",
       "      <td>3.812820</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>1.796357</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.056251</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>0.655767</td>\n",
       "      <td>0.335991</td>\n",
       "      <td>0.098588</td>\n",
       "      <td>0.706705</td>\n",
       "      <td>0.473348</td>\n",
       "      <td>0.726290</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047237</td>\n",
       "      <td>3.708139</td>\n",
       "      <td>2.910095</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>2.811760</td>\n",
       "      <td>3.038567</td>\n",
       "      <td>-0.054310</td>\n",
       "      <td>2.949162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456545</td>\n",
       "      <td>0.202658</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>0.738647</td>\n",
       "      <td>0.387145</td>\n",
       "      <td>0.150339</td>\n",
       "      <td>0.640531</td>\n",
       "      <td>0.420457</td>\n",
       "      <td>0.698610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.275433</td>\n",
       "      <td>3.773190</td>\n",
       "      <td>2.643662</td>\n",
       "      <td>-0.073327</td>\n",
       "      <td>2.295184</td>\n",
       "      <td>2.892549</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>2.130878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432633</td>\n",
       "      <td>0.148281</td>\n",
       "      <td>0.160235</td>\n",
       "      <td>0.758073</td>\n",
       "      <td>0.410296</td>\n",
       "      <td>0.160244</td>\n",
       "      <td>0.620352</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.709662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.060434</td>\n",
       "      <td>3.423417</td>\n",
       "      <td>2.893461</td>\n",
       "      <td>-0.089059</td>\n",
       "      <td>2.716601</td>\n",
       "      <td>2.856706</td>\n",
       "      <td>-0.087965</td>\n",
       "      <td>2.550269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419553</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.118061</td>\n",
       "      <td>0.684872</td>\n",
       "      <td>0.278488</td>\n",
       "      <td>0.105448</td>\n",
       "      <td>0.628054</td>\n",
       "      <td>0.470720</td>\n",
       "      <td>0.828787</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>6</td>\n",
       "      <td>273</td>\n",
       "      <td>-0.304880</td>\n",
       "      <td>22.298991</td>\n",
       "      <td>3.302567</td>\n",
       "      <td>-0.129734</td>\n",
       "      <td>14.958487</td>\n",
       "      <td>3.370847</td>\n",
       "      <td>-0.051861</td>\n",
       "      <td>15.985407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400836</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.256252</td>\n",
       "      <td>0.661555</td>\n",
       "      <td>0.268539</td>\n",
       "      <td>0.130888</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.310249</td>\n",
       "      <td>0.709654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>6</td>\n",
       "      <td>274</td>\n",
       "      <td>0.269868</td>\n",
       "      <td>33.843053</td>\n",
       "      <td>3.654818</td>\n",
       "      <td>0.212369</td>\n",
       "      <td>16.329158</td>\n",
       "      <td>2.957622</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>16.658380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552139</td>\n",
       "      <td>0.370040</td>\n",
       "      <td>0.223648</td>\n",
       "      <td>0.712328</td>\n",
       "      <td>0.506982</td>\n",
       "      <td>0.296971</td>\n",
       "      <td>0.870735</td>\n",
       "      <td>0.596865</td>\n",
       "      <td>0.785686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>6</td>\n",
       "      <td>275</td>\n",
       "      <td>0.696642</td>\n",
       "      <td>15.568775</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>0.337532</td>\n",
       "      <td>14.240621</td>\n",
       "      <td>4.116896</td>\n",
       "      <td>0.411972</td>\n",
       "      <td>16.540324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.293143</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>0.265822</td>\n",
       "      <td>0.706523</td>\n",
       "      <td>0.229444</td>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.610597</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.726543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>6</td>\n",
       "      <td>276</td>\n",
       "      <td>0.170718</td>\n",
       "      <td>26.607633</td>\n",
       "      <td>2.631762</td>\n",
       "      <td>-0.082792</td>\n",
       "      <td>16.046166</td>\n",
       "      <td>3.065634</td>\n",
       "      <td>-0.065649</td>\n",
       "      <td>16.759860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383266</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>0.214457</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.681577</td>\n",
       "      <td>0.318358</td>\n",
       "      <td>0.699691</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>6</td>\n",
       "      <td>277</td>\n",
       "      <td>-0.149774</td>\n",
       "      <td>25.667610</td>\n",
       "      <td>3.001896</td>\n",
       "      <td>-0.331184</td>\n",
       "      <td>15.513927</td>\n",
       "      <td>2.970890</td>\n",
       "      <td>-0.570239</td>\n",
       "      <td>19.720077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530426</td>\n",
       "      <td>0.263476</td>\n",
       "      <td>0.195801</td>\n",
       "      <td>0.788003</td>\n",
       "      <td>0.473607</td>\n",
       "      <td>0.175662</td>\n",
       "      <td>0.745219</td>\n",
       "      <td>0.345032</td>\n",
       "      <td>0.655788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4931 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Subject  Epoch  Mean_FC5  Variance_FC5  Kurtosis_FC5  Mean_FC3  \\\n",
       "0         15      1 -0.226124      3.195941      2.881555 -0.275889   \n",
       "1         15      2  0.030149      3.409489      3.228332  0.014870   \n",
       "2         15      3  0.047237      3.708139      2.910095 -0.005586   \n",
       "3         15      4 -0.275433      3.773190      2.643662 -0.073327   \n",
       "4         15      5 -0.060434      3.423417      2.893461 -0.089059   \n",
       "..       ...    ...       ...           ...           ...       ...   \n",
       "272        6    273 -0.304880     22.298991      3.302567 -0.129734   \n",
       "273        6    274  0.269868     33.843053      3.654818  0.212369   \n",
       "274        6    275  0.696642     15.568775      3.843750  0.337532   \n",
       "275        6    276  0.170718     26.607633      2.631762 -0.082792   \n",
       "276        6    277 -0.149774     25.667610      3.001896 -0.331184   \n",
       "\n",
       "     Variance_FC3  Kurtosis_FC3  Mean_FC1  Variance_FC1  ...  PLV_CP1_CP2  \\\n",
       "0        2.269788      3.280869 -0.109598      2.684536  ...     0.498464   \n",
       "1        2.478137      3.812820 -0.002679      1.796357  ...     0.266234   \n",
       "2        2.811760      3.038567 -0.054310      2.949162  ...     0.456545   \n",
       "3        2.295184      2.892549  0.087973      2.130878  ...     0.432633   \n",
       "4        2.716601      2.856706 -0.087965      2.550269  ...     0.419553   \n",
       "..            ...           ...       ...           ...  ...          ...   \n",
       "272     14.958487      3.370847 -0.051861     15.985407  ...     0.400836   \n",
       "273     16.329158      2.957622  0.039009     16.658380  ...     0.552139   \n",
       "274     14.240621      4.116896  0.411972     16.540324  ...     0.293143   \n",
       "275     16.046166      3.065634 -0.065649     16.759860  ...     0.383266   \n",
       "276     15.513927      2.970890 -0.570239     19.720077  ...     0.530426   \n",
       "\n",
       "     PLV_CP1_CP4  PLV_CP1_CP6  PLV_CPz_CP2  PLV_CPz_CP4  PLV_CPz_CP6  \\\n",
       "0       0.109177     0.096379     0.723574     0.384581     0.159108   \n",
       "1       0.056251     0.144260     0.655767     0.335991     0.098588   \n",
       "2       0.202658     0.047853     0.738647     0.387145     0.150339   \n",
       "3       0.148281     0.160235     0.758073     0.410296     0.160244   \n",
       "4       0.095825     0.118061     0.684872     0.278488     0.105448   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "272     0.100550     0.256252     0.661555     0.268539     0.130888   \n",
       "273     0.370040     0.223648     0.712328     0.506982     0.296971   \n",
       "274     0.119998     0.265822     0.706523     0.229444     0.090624   \n",
       "275     0.052075     0.214457     0.670556     0.267428     0.075736   \n",
       "276     0.263476     0.195801     0.788003     0.473607     0.175662   \n",
       "\n",
       "     PLV_CP2_CP4  PLV_CP2_CP6  PLV_CP4_CP6  Label  \n",
       "0       0.645515     0.389479     0.794813      1  \n",
       "1       0.706705     0.473348     0.726290      2  \n",
       "2       0.640531     0.420457     0.698610      1  \n",
       "3       0.620352     0.321739     0.709662      1  \n",
       "4       0.628054     0.470720     0.828787      1  \n",
       "..           ...          ...          ...    ...  \n",
       "272     0.714714     0.310249     0.709654      0  \n",
       "273     0.870735     0.596865     0.785686      0  \n",
       "274     0.610597     0.295000     0.726543      0  \n",
       "275     0.681577     0.318358     0.699691      0  \n",
       "276     0.745219     0.345032     0.655788      0  \n",
       "\n",
       "[4931 rows x 313 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx = features_all['Subject'] == subjects_train[0]\n",
    "features_train = features_all[train_idx]\n",
    "subjects_train2 = np.delete(subjects_train, 0, axis=None)\n",
    "for subject in subjects_train2 :\n",
    "    train_idx = features_all['Subject'] == subject\n",
    "    frames = [features_train, features_all[train_idx]]\n",
    "    features_train = pd.concat(frames)\n",
    "subjects_idx_train = features_train['Subject']\n",
    "features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean_FC5</th>\n",
       "      <th>Variance_FC5</th>\n",
       "      <th>Kurtosis_FC5</th>\n",
       "      <th>Mean_FC3</th>\n",
       "      <th>Variance_FC3</th>\n",
       "      <th>Kurtosis_FC3</th>\n",
       "      <th>Mean_FC1</th>\n",
       "      <th>Variance_FC1</th>\n",
       "      <th>Kurtosis_FC1</th>\n",
       "      <th>Mean_FC2</th>\n",
       "      <th>...</th>\n",
       "      <th>PLV_CP1_CPz</th>\n",
       "      <th>PLV_CP1_CP2</th>\n",
       "      <th>PLV_CP1_CP4</th>\n",
       "      <th>PLV_CP1_CP6</th>\n",
       "      <th>PLV_CPz_CP2</th>\n",
       "      <th>PLV_CPz_CP4</th>\n",
       "      <th>PLV_CPz_CP6</th>\n",
       "      <th>PLV_CP2_CP4</th>\n",
       "      <th>PLV_CP2_CP6</th>\n",
       "      <th>PLV_CP4_CP6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">15</th>\n",
       "      <th>1</th>\n",
       "      <td>-0.226124</td>\n",
       "      <td>3.195941</td>\n",
       "      <td>2.881555</td>\n",
       "      <td>-0.275889</td>\n",
       "      <td>2.269788</td>\n",
       "      <td>3.280869</td>\n",
       "      <td>-0.109598</td>\n",
       "      <td>2.684536</td>\n",
       "      <td>2.901555</td>\n",
       "      <td>-0.101212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610267</td>\n",
       "      <td>0.498464</td>\n",
       "      <td>0.109177</td>\n",
       "      <td>0.096379</td>\n",
       "      <td>0.723574</td>\n",
       "      <td>0.384581</td>\n",
       "      <td>0.159108</td>\n",
       "      <td>0.645515</td>\n",
       "      <td>0.389479</td>\n",
       "      <td>0.794813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030149</td>\n",
       "      <td>3.409489</td>\n",
       "      <td>3.228332</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>2.478137</td>\n",
       "      <td>3.812820</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>1.796357</td>\n",
       "      <td>2.764866</td>\n",
       "      <td>0.045633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519540</td>\n",
       "      <td>0.266234</td>\n",
       "      <td>0.056251</td>\n",
       "      <td>0.144260</td>\n",
       "      <td>0.655767</td>\n",
       "      <td>0.335991</td>\n",
       "      <td>0.098588</td>\n",
       "      <td>0.706705</td>\n",
       "      <td>0.473348</td>\n",
       "      <td>0.726290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047237</td>\n",
       "      <td>3.708139</td>\n",
       "      <td>2.910095</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>2.811760</td>\n",
       "      <td>3.038567</td>\n",
       "      <td>-0.054310</td>\n",
       "      <td>2.949162</td>\n",
       "      <td>3.309821</td>\n",
       "      <td>-0.171491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.601333</td>\n",
       "      <td>0.456545</td>\n",
       "      <td>0.202658</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>0.738647</td>\n",
       "      <td>0.387145</td>\n",
       "      <td>0.150339</td>\n",
       "      <td>0.640531</td>\n",
       "      <td>0.420457</td>\n",
       "      <td>0.698610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.275433</td>\n",
       "      <td>3.773190</td>\n",
       "      <td>2.643662</td>\n",
       "      <td>-0.073327</td>\n",
       "      <td>2.295184</td>\n",
       "      <td>2.892549</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>2.130878</td>\n",
       "      <td>2.651647</td>\n",
       "      <td>0.310267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.605191</td>\n",
       "      <td>0.432633</td>\n",
       "      <td>0.148281</td>\n",
       "      <td>0.160235</td>\n",
       "      <td>0.758073</td>\n",
       "      <td>0.410296</td>\n",
       "      <td>0.160244</td>\n",
       "      <td>0.620352</td>\n",
       "      <td>0.321739</td>\n",
       "      <td>0.709662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.060434</td>\n",
       "      <td>3.423417</td>\n",
       "      <td>2.893461</td>\n",
       "      <td>-0.089059</td>\n",
       "      <td>2.716601</td>\n",
       "      <td>2.856706</td>\n",
       "      <td>-0.087965</td>\n",
       "      <td>2.550269</td>\n",
       "      <td>3.046728</td>\n",
       "      <td>-0.186947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610368</td>\n",
       "      <td>0.419553</td>\n",
       "      <td>0.095825</td>\n",
       "      <td>0.118061</td>\n",
       "      <td>0.684872</td>\n",
       "      <td>0.278488</td>\n",
       "      <td>0.105448</td>\n",
       "      <td>0.628054</td>\n",
       "      <td>0.470720</td>\n",
       "      <td>0.828787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>273</th>\n",
       "      <td>-0.304880</td>\n",
       "      <td>22.298991</td>\n",
       "      <td>3.302567</td>\n",
       "      <td>-0.129734</td>\n",
       "      <td>14.958487</td>\n",
       "      <td>3.370847</td>\n",
       "      <td>-0.051861</td>\n",
       "      <td>15.985407</td>\n",
       "      <td>3.068512</td>\n",
       "      <td>-0.181406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749228</td>\n",
       "      <td>0.400836</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.256252</td>\n",
       "      <td>0.661555</td>\n",
       "      <td>0.268539</td>\n",
       "      <td>0.130888</td>\n",
       "      <td>0.714714</td>\n",
       "      <td>0.310249</td>\n",
       "      <td>0.709654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.269868</td>\n",
       "      <td>33.843053</td>\n",
       "      <td>3.654818</td>\n",
       "      <td>0.212369</td>\n",
       "      <td>16.329158</td>\n",
       "      <td>2.957622</td>\n",
       "      <td>0.039009</td>\n",
       "      <td>16.658380</td>\n",
       "      <td>3.534025</td>\n",
       "      <td>-0.243350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.818852</td>\n",
       "      <td>0.552139</td>\n",
       "      <td>0.370040</td>\n",
       "      <td>0.223648</td>\n",
       "      <td>0.712328</td>\n",
       "      <td>0.506982</td>\n",
       "      <td>0.296971</td>\n",
       "      <td>0.870735</td>\n",
       "      <td>0.596865</td>\n",
       "      <td>0.785686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.696642</td>\n",
       "      <td>15.568775</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>0.337532</td>\n",
       "      <td>14.240621</td>\n",
       "      <td>4.116896</td>\n",
       "      <td>0.411972</td>\n",
       "      <td>16.540324</td>\n",
       "      <td>4.061586</td>\n",
       "      <td>0.370064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634006</td>\n",
       "      <td>0.293143</td>\n",
       "      <td>0.119998</td>\n",
       "      <td>0.265822</td>\n",
       "      <td>0.706523</td>\n",
       "      <td>0.229444</td>\n",
       "      <td>0.090624</td>\n",
       "      <td>0.610597</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.726543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.170718</td>\n",
       "      <td>26.607633</td>\n",
       "      <td>2.631762</td>\n",
       "      <td>-0.082792</td>\n",
       "      <td>16.046166</td>\n",
       "      <td>3.065634</td>\n",
       "      <td>-0.065649</td>\n",
       "      <td>16.759860</td>\n",
       "      <td>3.330850</td>\n",
       "      <td>-0.213369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728297</td>\n",
       "      <td>0.383266</td>\n",
       "      <td>0.052075</td>\n",
       "      <td>0.214457</td>\n",
       "      <td>0.670556</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.075736</td>\n",
       "      <td>0.681577</td>\n",
       "      <td>0.318358</td>\n",
       "      <td>0.699691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>-0.149774</td>\n",
       "      <td>25.667610</td>\n",
       "      <td>3.001896</td>\n",
       "      <td>-0.331184</td>\n",
       "      <td>15.513927</td>\n",
       "      <td>2.970890</td>\n",
       "      <td>-0.570239</td>\n",
       "      <td>19.720077</td>\n",
       "      <td>3.202597</td>\n",
       "      <td>-0.779327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805974</td>\n",
       "      <td>0.530426</td>\n",
       "      <td>0.263476</td>\n",
       "      <td>0.195801</td>\n",
       "      <td>0.788003</td>\n",
       "      <td>0.473607</td>\n",
       "      <td>0.175662</td>\n",
       "      <td>0.745219</td>\n",
       "      <td>0.345032</td>\n",
       "      <td>0.655788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4931 rows × 310 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean_FC5  Variance_FC5  Kurtosis_FC5  Mean_FC3  Variance_FC3  \\\n",
       "Subject Epoch                                                                 \n",
       "15      1     -0.226124      3.195941      2.881555 -0.275889      2.269788   \n",
       "        2      0.030149      3.409489      3.228332  0.014870      2.478137   \n",
       "        3      0.047237      3.708139      2.910095 -0.005586      2.811760   \n",
       "        4     -0.275433      3.773190      2.643662 -0.073327      2.295184   \n",
       "        5     -0.060434      3.423417      2.893461 -0.089059      2.716601   \n",
       "...                 ...           ...           ...       ...           ...   \n",
       "6       273   -0.304880     22.298991      3.302567 -0.129734     14.958487   \n",
       "        274    0.269868     33.843053      3.654818  0.212369     16.329158   \n",
       "        275    0.696642     15.568775      3.843750  0.337532     14.240621   \n",
       "        276    0.170718     26.607633      2.631762 -0.082792     16.046166   \n",
       "        277   -0.149774     25.667610      3.001896 -0.331184     15.513927   \n",
       "\n",
       "               Kurtosis_FC3  Mean_FC1  Variance_FC1  Kurtosis_FC1  Mean_FC2  \\\n",
       "Subject Epoch                                                                 \n",
       "15      1          3.280869 -0.109598      2.684536      2.901555 -0.101212   \n",
       "        2          3.812820 -0.002679      1.796357      2.764866  0.045633   \n",
       "        3          3.038567 -0.054310      2.949162      3.309821 -0.171491   \n",
       "        4          2.892549  0.087973      2.130878      2.651647  0.310267   \n",
       "        5          2.856706 -0.087965      2.550269      3.046728 -0.186947   \n",
       "...                     ...       ...           ...           ...       ...   \n",
       "6       273        3.370847 -0.051861     15.985407      3.068512 -0.181406   \n",
       "        274        2.957622  0.039009     16.658380      3.534025 -0.243350   \n",
       "        275        4.116896  0.411972     16.540324      4.061586  0.370064   \n",
       "        276        3.065634 -0.065649     16.759860      3.330850 -0.213369   \n",
       "        277        2.970890 -0.570239     19.720077      3.202597 -0.779327   \n",
       "\n",
       "               ...  PLV_CP1_CPz  PLV_CP1_CP2  PLV_CP1_CP4  PLV_CP1_CP6  \\\n",
       "Subject Epoch  ...                                                       \n",
       "15      1      ...     0.610267     0.498464     0.109177     0.096379   \n",
       "        2      ...     0.519540     0.266234     0.056251     0.144260   \n",
       "        3      ...     0.601333     0.456545     0.202658     0.047853   \n",
       "        4      ...     0.605191     0.432633     0.148281     0.160235   \n",
       "        5      ...     0.610368     0.419553     0.095825     0.118061   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "6       273    ...     0.749228     0.400836     0.100550     0.256252   \n",
       "        274    ...     0.818852     0.552139     0.370040     0.223648   \n",
       "        275    ...     0.634006     0.293143     0.119998     0.265822   \n",
       "        276    ...     0.728297     0.383266     0.052075     0.214457   \n",
       "        277    ...     0.805974     0.530426     0.263476     0.195801   \n",
       "\n",
       "               PLV_CPz_CP2  PLV_CPz_CP4  PLV_CPz_CP6  PLV_CP2_CP4  \\\n",
       "Subject Epoch                                                       \n",
       "15      1         0.723574     0.384581     0.159108     0.645515   \n",
       "        2         0.655767     0.335991     0.098588     0.706705   \n",
       "        3         0.738647     0.387145     0.150339     0.640531   \n",
       "        4         0.758073     0.410296     0.160244     0.620352   \n",
       "        5         0.684872     0.278488     0.105448     0.628054   \n",
       "...                    ...          ...          ...          ...   \n",
       "6       273       0.661555     0.268539     0.130888     0.714714   \n",
       "        274       0.712328     0.506982     0.296971     0.870735   \n",
       "        275       0.706523     0.229444     0.090624     0.610597   \n",
       "        276       0.670556     0.267428     0.075736     0.681577   \n",
       "        277       0.788003     0.473607     0.175662     0.745219   \n",
       "\n",
       "               PLV_CP2_CP6  PLV_CP4_CP6  \n",
       "Subject Epoch                            \n",
       "15      1         0.389479     0.794813  \n",
       "        2         0.473348     0.726290  \n",
       "        3         0.420457     0.698610  \n",
       "        4         0.321739     0.709662  \n",
       "        5         0.470720     0.828787  \n",
       "...                    ...          ...  \n",
       "6       273       0.310249     0.709654  \n",
       "        274       0.596865     0.785686  \n",
       "        275       0.295000     0.726543  \n",
       "        276       0.318358     0.699691  \n",
       "        277       0.345032     0.655788  \n",
       "\n",
       "[4931 rows x 310 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.index = [features_train['Subject'], features_train['Epoch']]\n",
    "X_train = features_train.drop(['Subject','Epoch','Label'], axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1737, 2: 1701, 0: 1493})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = features_train['Label']\n",
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>PSD_FC1_D3</th>\n",
       "      <th>PSD_Cz_D3</th>\n",
       "      <th>PSD_CP1_D3</th>\n",
       "      <th>PSD_CP2_D3</th>\n",
       "      <th>PLV_FC5_FC1</th>\n",
       "      <th>PLV_FC5_CP5</th>\n",
       "      <th>PLV_FC3_C1</th>\n",
       "      <th>PLV_FC3_CP1</th>\n",
       "      <th>PLV_FC1_FC2</th>\n",
       "      <th>PLV_FC1_C3</th>\n",
       "      <th>PLV_FC1_C2</th>\n",
       "      <th>PLV_FC1_CPz</th>\n",
       "      <th>PLV_C5_CP6</th>\n",
       "      <th>PLV_C3_C1</th>\n",
       "      <th>PLV_Cz_C4</th>\n",
       "      <th>PLV_C2_C4</th>\n",
       "      <th>PLV_CP5_CP3</th>\n",
       "      <th>PLV_CP5_CP6</th>\n",
       "      <th>PLV_CP3_CP2</th>\n",
       "      <th>PLV_CP4_CP6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subject</th>\n",
       "      <th>Epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">15</th>\n",
       "      <th>1</th>\n",
       "      <td>0.034486</td>\n",
       "      <td>0.076231</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.044284</td>\n",
       "      <td>0.328939</td>\n",
       "      <td>0.274523</td>\n",
       "      <td>0.666815</td>\n",
       "      <td>0.648738</td>\n",
       "      <td>0.686277</td>\n",
       "      <td>0.700358</td>\n",
       "      <td>0.570172</td>\n",
       "      <td>0.507703</td>\n",
       "      <td>0.194724</td>\n",
       "      <td>0.631169</td>\n",
       "      <td>0.327217</td>\n",
       "      <td>0.604345</td>\n",
       "      <td>0.425065</td>\n",
       "      <td>0.194597</td>\n",
       "      <td>0.213017</td>\n",
       "      <td>0.794813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028806</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>0.028159</td>\n",
       "      <td>0.033061</td>\n",
       "      <td>0.422381</td>\n",
       "      <td>0.201130</td>\n",
       "      <td>0.644448</td>\n",
       "      <td>0.581876</td>\n",
       "      <td>0.576222</td>\n",
       "      <td>0.675428</td>\n",
       "      <td>0.454940</td>\n",
       "      <td>0.415534</td>\n",
       "      <td>0.168461</td>\n",
       "      <td>0.617415</td>\n",
       "      <td>0.196764</td>\n",
       "      <td>0.591272</td>\n",
       "      <td>0.473716</td>\n",
       "      <td>0.142296</td>\n",
       "      <td>0.210151</td>\n",
       "      <td>0.726290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035788</td>\n",
       "      <td>0.073811</td>\n",
       "      <td>0.034063</td>\n",
       "      <td>0.042011</td>\n",
       "      <td>0.404427</td>\n",
       "      <td>0.251832</td>\n",
       "      <td>0.668037</td>\n",
       "      <td>0.626021</td>\n",
       "      <td>0.709359</td>\n",
       "      <td>0.745186</td>\n",
       "      <td>0.614729</td>\n",
       "      <td>0.480164</td>\n",
       "      <td>0.042859</td>\n",
       "      <td>0.674037</td>\n",
       "      <td>0.340390</td>\n",
       "      <td>0.585532</td>\n",
       "      <td>0.434534</td>\n",
       "      <td>0.250633</td>\n",
       "      <td>0.207092</td>\n",
       "      <td>0.698610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029694</td>\n",
       "      <td>0.059838</td>\n",
       "      <td>0.027287</td>\n",
       "      <td>0.037784</td>\n",
       "      <td>0.295600</td>\n",
       "      <td>0.238209</td>\n",
       "      <td>0.560659</td>\n",
       "      <td>0.517382</td>\n",
       "      <td>0.648619</td>\n",
       "      <td>0.649738</td>\n",
       "      <td>0.526301</td>\n",
       "      <td>0.508942</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.590852</td>\n",
       "      <td>0.317237</td>\n",
       "      <td>0.589996</td>\n",
       "      <td>0.376382</td>\n",
       "      <td>0.156909</td>\n",
       "      <td>0.238464</td>\n",
       "      <td>0.709662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.026469</td>\n",
       "      <td>0.040255</td>\n",
       "      <td>0.024066</td>\n",
       "      <td>0.030912</td>\n",
       "      <td>0.437315</td>\n",
       "      <td>0.303521</td>\n",
       "      <td>0.759739</td>\n",
       "      <td>0.724280</td>\n",
       "      <td>0.659948</td>\n",
       "      <td>0.773086</td>\n",
       "      <td>0.603110</td>\n",
       "      <td>0.559794</td>\n",
       "      <td>0.150218</td>\n",
       "      <td>0.774976</td>\n",
       "      <td>0.266988</td>\n",
       "      <td>0.557998</td>\n",
       "      <td>0.491774</td>\n",
       "      <td>0.254824</td>\n",
       "      <td>0.117975</td>\n",
       "      <td>0.828787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">6</th>\n",
       "      <th>273</th>\n",
       "      <td>0.242868</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.074924</td>\n",
       "      <td>0.114307</td>\n",
       "      <td>0.300043</td>\n",
       "      <td>0.308553</td>\n",
       "      <td>0.650554</td>\n",
       "      <td>0.344405</td>\n",
       "      <td>0.625155</td>\n",
       "      <td>0.542170</td>\n",
       "      <td>0.483756</td>\n",
       "      <td>0.487275</td>\n",
       "      <td>0.251002</td>\n",
       "      <td>0.647679</td>\n",
       "      <td>0.298595</td>\n",
       "      <td>0.704364</td>\n",
       "      <td>0.621519</td>\n",
       "      <td>0.229030</td>\n",
       "      <td>0.134593</td>\n",
       "      <td>0.709654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.257755</td>\n",
       "      <td>0.198752</td>\n",
       "      <td>0.089106</td>\n",
       "      <td>0.107626</td>\n",
       "      <td>0.421420</td>\n",
       "      <td>0.219168</td>\n",
       "      <td>0.663909</td>\n",
       "      <td>0.364445</td>\n",
       "      <td>0.601041</td>\n",
       "      <td>0.573837</td>\n",
       "      <td>0.399727</td>\n",
       "      <td>0.364564</td>\n",
       "      <td>0.318455</td>\n",
       "      <td>0.719368</td>\n",
       "      <td>0.452053</td>\n",
       "      <td>0.815618</td>\n",
       "      <td>0.489901</td>\n",
       "      <td>0.222150</td>\n",
       "      <td>0.351906</td>\n",
       "      <td>0.785686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.123824</td>\n",
       "      <td>0.128342</td>\n",
       "      <td>0.070091</td>\n",
       "      <td>0.076460</td>\n",
       "      <td>0.503686</td>\n",
       "      <td>0.287101</td>\n",
       "      <td>0.728531</td>\n",
       "      <td>0.537757</td>\n",
       "      <td>0.638831</td>\n",
       "      <td>0.343031</td>\n",
       "      <td>0.564578</td>\n",
       "      <td>0.585509</td>\n",
       "      <td>0.345457</td>\n",
       "      <td>0.653562</td>\n",
       "      <td>0.429753</td>\n",
       "      <td>0.782901</td>\n",
       "      <td>0.772894</td>\n",
       "      <td>0.322103</td>\n",
       "      <td>0.125312</td>\n",
       "      <td>0.726543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.515490</td>\n",
       "      <td>0.347935</td>\n",
       "      <td>0.110243</td>\n",
       "      <td>0.164176</td>\n",
       "      <td>0.423568</td>\n",
       "      <td>0.243886</td>\n",
       "      <td>0.620636</td>\n",
       "      <td>0.392398</td>\n",
       "      <td>0.559320</td>\n",
       "      <td>0.509189</td>\n",
       "      <td>0.435446</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.285531</td>\n",
       "      <td>0.697862</td>\n",
       "      <td>0.278913</td>\n",
       "      <td>0.716274</td>\n",
       "      <td>0.652634</td>\n",
       "      <td>0.176325</td>\n",
       "      <td>0.129566</td>\n",
       "      <td>0.699691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.505996</td>\n",
       "      <td>0.253699</td>\n",
       "      <td>0.108354</td>\n",
       "      <td>0.124724</td>\n",
       "      <td>0.427082</td>\n",
       "      <td>0.267295</td>\n",
       "      <td>0.733090</td>\n",
       "      <td>0.428935</td>\n",
       "      <td>0.745127</td>\n",
       "      <td>0.593039</td>\n",
       "      <td>0.669092</td>\n",
       "      <td>0.494826</td>\n",
       "      <td>0.145324</td>\n",
       "      <td>0.749290</td>\n",
       "      <td>0.524799</td>\n",
       "      <td>0.763347</td>\n",
       "      <td>0.575439</td>\n",
       "      <td>0.081943</td>\n",
       "      <td>0.230565</td>\n",
       "      <td>0.655788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4931 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               PSD_FC1_D3  PSD_Cz_D3  PSD_CP1_D3  PSD_CP2_D3  PLV_FC5_FC1  \\\n",
       "Subject Epoch                                                               \n",
       "15      1        0.034486   0.076231    0.027698    0.044284     0.328939   \n",
       "        2        0.028806   0.060074    0.028159    0.033061     0.422381   \n",
       "        3        0.035788   0.073811    0.034063    0.042011     0.404427   \n",
       "        4        0.029694   0.059838    0.027287    0.037784     0.295600   \n",
       "        5        0.026469   0.040255    0.024066    0.030912     0.437315   \n",
       "...                   ...        ...         ...         ...          ...   \n",
       "6       273      0.242868   0.132700    0.074924    0.114307     0.300043   \n",
       "        274      0.257755   0.198752    0.089106    0.107626     0.421420   \n",
       "        275      0.123824   0.128342    0.070091    0.076460     0.503686   \n",
       "        276      0.515490   0.347935    0.110243    0.164176     0.423568   \n",
       "        277      0.505996   0.253699    0.108354    0.124724     0.427082   \n",
       "\n",
       "               PLV_FC5_CP5  PLV_FC3_C1  PLV_FC3_CP1  PLV_FC1_FC2  PLV_FC1_C3  \\\n",
       "Subject Epoch                                                                  \n",
       "15      1         0.274523    0.666815     0.648738     0.686277    0.700358   \n",
       "        2         0.201130    0.644448     0.581876     0.576222    0.675428   \n",
       "        3         0.251832    0.668037     0.626021     0.709359    0.745186   \n",
       "        4         0.238209    0.560659     0.517382     0.648619    0.649738   \n",
       "        5         0.303521    0.759739     0.724280     0.659948    0.773086   \n",
       "...                    ...         ...          ...          ...         ...   \n",
       "6       273       0.308553    0.650554     0.344405     0.625155    0.542170   \n",
       "        274       0.219168    0.663909     0.364445     0.601041    0.573837   \n",
       "        275       0.287101    0.728531     0.537757     0.638831    0.343031   \n",
       "        276       0.243886    0.620636     0.392398     0.559320    0.509189   \n",
       "        277       0.267295    0.733090     0.428935     0.745127    0.593039   \n",
       "\n",
       "               PLV_FC1_C2  PLV_FC1_CPz  PLV_C5_CP6  PLV_C3_C1  PLV_Cz_C4  \\\n",
       "Subject Epoch                                                              \n",
       "15      1        0.570172     0.507703    0.194724   0.631169   0.327217   \n",
       "        2        0.454940     0.415534    0.168461   0.617415   0.196764   \n",
       "        3        0.614729     0.480164    0.042859   0.674037   0.340390   \n",
       "        4        0.526301     0.508942    0.049900   0.590852   0.317237   \n",
       "        5        0.603110     0.559794    0.150218   0.774976   0.266988   \n",
       "...                   ...          ...         ...        ...        ...   \n",
       "6       273      0.483756     0.487275    0.251002   0.647679   0.298595   \n",
       "        274      0.399727     0.364564    0.318455   0.719368   0.452053   \n",
       "        275      0.564578     0.585509    0.345457   0.653562   0.429753   \n",
       "        276      0.435446     0.433962    0.285531   0.697862   0.278913   \n",
       "        277      0.669092     0.494826    0.145324   0.749290   0.524799   \n",
       "\n",
       "               PLV_C2_C4  PLV_CP5_CP3  PLV_CP5_CP6  PLV_CP3_CP2  PLV_CP4_CP6  \n",
       "Subject Epoch                                                                 \n",
       "15      1       0.604345     0.425065     0.194597     0.213017     0.794813  \n",
       "        2       0.591272     0.473716     0.142296     0.210151     0.726290  \n",
       "        3       0.585532     0.434534     0.250633     0.207092     0.698610  \n",
       "        4       0.589996     0.376382     0.156909     0.238464     0.709662  \n",
       "        5       0.557998     0.491774     0.254824     0.117975     0.828787  \n",
       "...                  ...          ...          ...          ...          ...  \n",
       "6       273     0.704364     0.621519     0.229030     0.134593     0.709654  \n",
       "        274     0.815618     0.489901     0.222150     0.351906     0.785686  \n",
       "        275     0.782901     0.772894     0.322103     0.125312     0.726543  \n",
       "        276     0.716274     0.652634     0.176325     0.129566     0.699691  \n",
       "        277     0.763347     0.575439     0.081943     0.230565     0.655788  \n",
       "\n",
       "[4931 rows x 20 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = ['PSD_FC1_D3', 'PSD_Cz_D3', 'PSD_CP1_D3', 'PSD_CP2_D3', 'PLV_FC5_FC1',\n",
    "                       'PLV_FC5_CP5', 'PLV_FC3_C1', 'PLV_FC3_CP1', 'PLV_FC1_FC2', 'PLV_FC1_C3',\n",
    "                       'PLV_FC1_C2', 'PLV_FC1_CPz', 'PLV_C5_CP6', 'PLV_C3_C1', 'PLV_Cz_C4',\n",
    "                       'PLV_C2_C4', 'PLV_CP5_CP3', 'PLV_CP5_CP6', 'PLV_CP3_CP2','PLV_CP4_CP6']\n",
    "X_train = X_train[selected_features]\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PSD_FC1_D3', 'PSD_Cz_D3', 'PSD_CP1_D3', 'PSD_CP2_D3', 'PLV_FC5_FC1',\n",
       "       'PLV_FC5_CP5', 'PLV_FC3_C1', 'PLV_FC3_CP1', 'PLV_FC1_FC2', 'PLV_FC1_C3',\n",
       "       'PLV_FC1_C2', 'PLV_FC1_CPz', 'PLV_C5_CP6', 'PLV_C3_C1', 'PLV_Cz_C4',\n",
       "       'PLV_C2_C4', 'PLV_CP5_CP3', 'PLV_CP5_CP6', 'PLV_CP3_CP2',\n",
       "       'PLV_CP4_CP6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess the features matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4931, 20)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standardizer = StandardScaler()\n",
    "X_scaled_train = standardizer.fit_transform(X_train)\n",
    "normalizer = MinMaxScaler(feature_range=(0,1))\n",
    "X_scaled_train = normalizer.fit_transform(X_scaled_train)\n",
    "X_scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1737, 2: 1701, 0: 1493})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-check SVCL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model list\n",
    "models = define_models_svcl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.33676975945017185, 0.3445378151260504, 0.34265734265734266, 0.3248175182481752, 0.3273381294964029, 0.38461538461538464, 0.3474178403755869, 0.35, 0.3684210526315789, 0.36046511627906974, 0.3333333333333333, 0.4397905759162304, 0.39285714285714285, 0.34615384615384615, 0.33444816053511706, 0.36666666666666664, 0.34558823529411764, 0.34980988593155893, 0.33574007220216606], 'roc_auc': [0.7406519213485608, 0.5287463198552251, 0.7684760271862369, 0.7599204524855971, 0.7176318483931418, 0.6273603238866398, 0.6807057057057057, 0.6318175526024362, 0.7618339002267573, 0.7443899709403992, 0.7917811484874303, 0.5904735797827904, 0.7679830520616672, 0.7427119828161496, 0.6340245791245792, 0.722723063973064, 0.6889364850218342, 0.590119977734041, 0.7711480125744595], 'f1': [0.16968347776923826, 0.17657563025210082, 0.17489801864801863, 0.15927690977458728, 0.16145132674348328, 0.2136752136752137, 0.1791562382424629, 0.18148148148148147, 0.19838056680161945, 0.19101570264360962, 0.16666666666666666, 0.2686720609233698, 0.2216117216117216, 0.178021978021978, 0.1676431882381539, 0.19674796747967477, 0.17751526840244292, 0.18130991270818833, 0.16877744170162945]}\n",
      "svm1 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3025210084033613, 0.43006993006993005, 0.4416058394160584, 0.4568345323741007, 0.4115384615384615, 0.4225352112676056, 0.35714285714285715, 0.531578947368421, 0.5271317829457365, 0.5448028673835126, 0.4397905759162304, 0.5595238095238095, 0.4461538461538462, 0.3411371237458194, 0.36666666666666664, 0.47794117647058826, 0.34980988593155893, 0.47653429602888087], 'roc_auc': [0.7343024105453138, 0.5427578802366098, 0.8776049369022972, 0.7617712194570908, 0.7250827976578952, 0.6193130904183536, 0.6575947822822822, 0.6457122093023256, 0.7678445452254975, 0.7456593413581073, 0.7929399594934399, 0.6054470931115667, 0.7716818382162774, 0.7488843009676343, 0.6113563973063973, 0.6995938552188553, 0.7096943203946807, 0.6055903461163794, 0.7270952489895524], 'f1': [0.4203510212159305, 0.23048048984274652, 0.32612294072968223, 0.34748401710316523, 0.3569248845153215, 0.2665235103266265, 0.3167223539255334, 0.19640784747167722, 0.471909369837149, 0.4207278509604091, 0.43867197569589195, 0.2696526158902434, 0.4367541061089449, 0.34730633902551095, 0.18160335244347692, 0.19674796747967477, 0.381866426129197, 0.18130991270818833, 0.38811441266314917]}\n",
      "svm2 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3739495798319328, 0.6958041958041958, 0.48175182481751827, 0.5431654676258992, 0.5884615384615385, 0.5539906103286385, 0.475, 0.5684210526315789, 0.5775193798449613, 0.5913978494623656, 0.5497382198952879, 0.5277777777777778, 0.6076923076923076, 0.5117056856187291, 0.4925925925925926, 0.5183823529411765, 0.38022813688212925, 0.5956678700361011], 'roc_auc': [0.7336904579232337, 0.5976149960835156, 0.9134794316277235, 0.7343529846518132, 0.737814906182253, 0.8266032388663968, 0.7322691441441441, 0.710969222960502, 0.7996771856890904, 0.7759745352265526, 0.7992833614225804, 0.6916320156451735, 0.7677077300229121, 0.7672432849516183, 0.7580974747474748, 0.7429622615039282, 0.7497994216507688, 0.6791390827220135, 0.7891191523255124], 'f1': [0.4271432123049446, 0.3078650984307242, 0.6792747768728131, 0.46064394581576823, 0.4786513066152377, 0.5573840168353065, 0.5427512338604453, 0.4116767194678097, 0.5650373310547541, 0.5721552285753132, 0.5510841138429459, 0.511253010912903, 0.5189162760239913, 0.5952393760086068, 0.4985400324442553, 0.4195759709907984, 0.4797777214285131, 0.3063288180799812, 0.5897567614263927]}\n",
      "svm3 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5085910652920962, 0.3949579831932773, 0.5804195804195804, 0.4562043795620438, 0.49280575539568344, 0.6307692307692307, 0.5305164319248826, 0.5071428571428571, 0.6157894736842106, 0.6317829457364341, 0.5089605734767025, 0.5130890052356021, 0.5317460317460317, 0.5692307692307692, 0.5953177257525084, 0.5111111111111111, 0.5588235294117647, 0.41064638783269963, 0.5523465703971119], 'roc_auc': [0.7287279788392264, 0.6230680928071739, 0.9197426026570049, 0.7097557793230754, 0.710622500636259, 0.8685870445344129, 0.7282394894894896, 0.7323241312028688, 0.8219749937011841, 0.7943712655445548, 0.7655911905487457, 0.7088614054074581, 0.7535652230928105, 0.7665858566900233, 0.7979518518518519, 0.7391435185185186, 0.757786352577162, 0.693642522017455, 0.786670564410212], 'f1': [0.43359746148219636, 0.336956191178061, 0.5517423143730856, 0.38592905285505663, 0.41973492634463855, 0.6110904667971493, 0.5227204945718591, 0.4424612694213393, 0.6110948870812478, 0.6298603225907357, 0.44664761347188947, 0.4326335089104598, 0.5144732883863319, 0.54977925229576, 0.5961715095930598, 0.4461192282205194, 0.5277224882497594, 0.3503756039796118, 0.5377835755240725]}\n",
      "svm4 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3949579831932773, 0.5629370629370629, 0.4708029197080292, 0.4568345323741007, 0.6461538461538462, 0.48826291079812206, 0.5107142857142857, 0.6, 0.6356589147286822, 0.48028673835125446, 0.518324607329843, 0.503968253968254, 0.573076923076923, 0.6153846153846154, 0.5259259259259259, 0.5441176470588235, 0.41825095057034223, 0.5595667870036101], 'roc_auc': [0.7236032866422617, 0.6274451016935418, 0.9161440617913832, 0.7048740366335394, 0.6892666685145473, 0.8736113360323886, 0.7134933370870872, 0.73312585693192, 0.820486898463089, 0.7967380545116566, 0.7312155492121537, 0.7058792815371763, 0.7465143076394428, 0.7691279821488156, 0.8020730639730639, 0.7391351010101009, 0.7591541979789258, 0.6932414365519572, 0.781772541244058], 'f1': [0.44410612173708436, 0.34176420619617914, 0.5314472642203735, 0.4022383552245707, 0.37777795300115763, 0.6281004051153001, 0.47950990174544267, 0.4456000363410337, 0.5944185184040548, 0.6338411474526385, 0.4117619961505401, 0.43550101220167126, 0.48061014605479213, 0.5543387646835922, 0.6182361627090243, 0.47195094589079983, 0.5112719228925212, 0.35642652866817875, 0.5480714537738928]}\n",
      "svm5 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5189003436426117, 0.3907563025210084, 0.5629370629370629, 0.4708029197080292, 0.44964028776978415, 0.6423076923076924, 0.5023474178403756, 0.5071428571428571, 0.5947368421052631, 0.6201550387596899, 0.48028673835125446, 0.5078534031413613, 0.5079365079365079, 0.573076923076923, 0.6120401337792643, 0.5259259259259259, 0.5441176470588235, 0.41825095057034223, 0.5595667870036101], 'roc_auc': [0.7239021387287461, 0.627781379142695, 0.9155448184708667, 0.7039254474109842, 0.6868474146048097, 0.8741255060728745, 0.7084614301801802, 0.7340697180034805, 0.8192979969765686, 0.7962272329367578, 0.7200277368358862, 0.7029090244550771, 0.7468822131642182, 0.7710554304304305, 0.8034427609427609, 0.7381544612794612, 0.7588920069977559, 0.6931648973181447, 0.7806862570646601], 'f1': [0.44703343095231035, 0.33754576651740725, 0.5314472642203735, 0.4022383552245707, 0.36865910497408527, 0.6240798217897455, 0.49479421591341516, 0.4424859169199595, 0.590257925876669, 0.6167342385704827, 0.41706818493662257, 0.41909718657403666, 0.4856378629112715, 0.5543387646835922, 0.6153083463354325, 0.47541379934768885, 0.5112719228925212, 0.35642652866817875, 0.5488395258458744]}\n",
      "svm6 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5189003436426117, 0.3907563025210084, 0.5629370629370629, 0.4708029197080292, 0.44964028776978415, 0.6461538461538462, 0.49765258215962443, 0.5071428571428571, 0.5947368421052631, 0.6201550387596899, 0.48028673835125446, 0.5078534031413613, 0.5079365079365079, 0.573076923076923, 0.6120401337792643, 0.5259259259259259, 0.5441176470588235, 0.41825095057034223, 0.555956678700361], 'roc_auc': [0.7233124721424552, 0.6275950085082246, 0.9168931159420289, 0.704293893213329, 0.6869280494022525, 0.8743117408906883, 0.7089264264264264, 0.7347470238095237, 0.8189673091458807, 0.7958019898725914, 0.7186276277957093, 0.7035474576592998, 0.7464657392533339, 0.7708239489489489, 0.8030604377104377, 0.7384490740740741, 0.7592337997004815, 0.6930177829466612, 0.7806750298685783], 'f1': [0.44703343095231035, 0.33754576651740725, 0.5314472642203735, 0.4022383552245707, 0.36865910497408527, 0.6295246098692641, 0.4890164608474468, 0.4424859169199595, 0.589942601629256, 0.6167342385704827, 0.4174846623892943, 0.41909718657403666, 0.4856378629112715, 0.5543387646835922, 0.6155152587663061, 0.47541379934768885, 0.5112955749856603, 0.35642652866817875, 0.5444033713559644]}\n",
      "svm7 evaluated\n",
      "\n",
      "Rank=1, Name=svm3, Accuracy=0.534, roc_auc=0.753, f1=0.499\n",
      "Rank=2, Name=svm4, Accuracy=0.532, roc_auc=0.758, f1=0.492\n",
      "Rank=3, Name=svm5, Accuracy=0.527, roc_auc=0.754, f1=0.488\n",
      "Rank=4, Name=svm6, Accuracy=0.526, roc_auc=0.753, f1=0.486\n",
      "Rank=5, Name=svm7, Accuracy=0.525, roc_auc=0.753, f1=0.486\n",
      "Rank=6, Name=svm2, Accuracy=0.442, roc_auc=0.703, f1=0.325\n",
      "Rank=7, Name=svm1, Accuracy=0.354, roc_auc=0.698, f1=0.186\n",
      "0.35428567777736536 ['svm3', 'svm4', 'svm5', 'svm6', 'svm7', 'svm2', 'svm1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate models\n",
    "results = evaluate_models(X_scaled_train, Y_train, models, subjects_train)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing the data we obtain that the best three models are Logistic, LDA and SCVL with mean estimated accuracies of 0.509, 0.504 and 0.494 respectively. Let's try to normalize the standardized dataset to see if we can improve the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-check logistic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model list\n",
    "models = define_models_logistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.44673539518900346, 0.35294117647058826, 0.44755244755244755, 0.38321167883211676, 0.5179856115107914, 0.38846153846153847, 0.38967136150234744, 0.3678571428571429, 0.3526315789473684, 0.4728682170542636, 0.5519713261648745, 0.45549738219895286, 0.5317460317460317, 0.4269230769230769, 0.33444816053511706, 0.3925925925925926, 0.375, 0.38022813688212925, 0.4404332129963899], 'roc_auc': [0.7360962537539183, 0.5270831645193529, 0.8149836247904959, 0.7578082925919407, 0.7141275944876035, 0.6007395411605938, 0.6738424361861862, 0.6565441583610189, 0.7573837868480725, 0.750236069514126, 0.7839804225203206, 0.581766917293233, 0.7707241303526914, 0.7132132132132133, 0.5983072390572391, 0.7036019921436588, 0.6879965550893382, 0.600236824317608, 0.7537435284747113], 'f1': [0.35331193231821006, 0.31494477314910746, 0.3532934134667909, 0.2839364990773357, 0.5204046277209351, 0.22292763259149814, 0.27039291934348547, 0.22470133667502087, 0.2764033820947705, 0.40211774954511775, 0.46662986172441695, 0.3144450858997073, 0.45077877153541984, 0.32951130284889874, 0.1676431882381539, 0.25480193236714976, 0.25602746113582026, 0.26780893230472047, 0.362186508812446]}\n",
      "logistic1 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5085910652920962, 0.3487394957983193, 0.7307692307692307, 0.5218978102189781, 0.4892086330935252, 0.48846153846153845, 0.5586854460093896, 0.45, 0.6052631578947368, 0.5387596899224806, 0.5949820788530465, 0.518324607329843, 0.5079365079365079, 0.5884615384615385, 0.35451505016722407, 0.4888888888888889, 0.4889705882352941, 0.38022813688212925, 0.6209386281588448], 'roc_auc': [0.7398255113001162, 0.5534465062258596, 0.8773222604259096, 0.757998754771406, 0.7234100455838589, 0.698800269905533, 0.7058028340840842, 0.6830530177187154, 0.7797619047619048, 0.7613390201975884, 0.7922871695367452, 0.6249798264600895, 0.7740097816729623, 0.738697030363697, 0.6606867003367003, 0.740283389450056, 0.7121021600399358, 0.6357256813979841, 0.7728062482523704], 'f1': [0.40777133447880876, 0.2757729187412633, 0.730682818032319, 0.5309996323131329, 0.4275110992287251, 0.4396993227290447, 0.5516276273471747, 0.38686949591123, 0.6117445460436316, 0.5217957183237235, 0.5534463019244048, 0.4963762960200591, 0.4916274630456854, 0.5918748986510084, 0.2686861165865624, 0.4163288778121314, 0.4400482067985655, 0.3132505489346338, 0.6134711019382535]}\n",
      "logistic2 evaluated\n",
      "15\n",
      "12\n",
      "21\n",
      "4\n",
      "10\n",
      "44\n",
      "3\n",
      "18\n",
      "29\n",
      "20\n",
      "7\n",
      "19\n",
      "11\n",
      "2\n",
      "28\n",
      "5\n",
      "8\n",
      "16\n",
      "6\n",
      "{'accuracy': [0.5223367697594502, 0.3403361344537815, 0.6538461538461539, 0.4708029197080292, 0.539568345323741, 0.5807692307692308, 0.568075117370892, 0.4928571428571429, 0.6210526315789474, 0.5891472868217055, 0.5376344086021505, 0.5445026178010471, 0.5396825396825397, 0.5846153846153846, 0.5250836120401338, 0.4962962962962963, 0.5110294117647058, 0.4068441064638783, 0.5848375451263538], 'roc_auc': [0.7426543764659462, 0.5964278961726495, 0.9211937265848369, 0.7378844161655541, 0.733086431263455, 0.834033738191633, 0.7411350412912913, 0.7156481536413014, 0.8119976694381457, 0.7813707504837968, 0.795441871842551, 0.7030134521910837, 0.7663305127243101, 0.7601731940273607, 0.7640580808080809, 0.7470889450056116, 0.7431560508551565, 0.6876217669628834, 0.7897029665217724], 'f1': [0.43013599420904364, 0.26203206469980506, 0.6358882174079289, 0.4276567342664834, 0.4942316593635404, 0.5499818869853057, 0.5657503334708816, 0.43081033362879173, 0.611647859419416, 0.5833439643723202, 0.4574224812693309, 0.49503953341840895, 0.5221569606189501, 0.5726445398894098, 0.5154781765315498, 0.42677826710802425, 0.4697807937404168, 0.3475101386304703, 0.5750978712256591]}\n",
      "logistic3 evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'accuracy': [0.5085910652920962, 0.3865546218487395, 0.5734265734265734, 0.4744525547445255, 0.5035971223021583, 0.65, 0.5539906103286385, 0.5035714285714286, 0.5947368421052631, 0.5968992248062015, 0.5053763440860215, 0.5130890052356021, 0.5238095238095238, 0.573076923076923, 0.5986622073578596, 0.5148148148148148, 0.5367647058823529, 0.4220532319391635, 0.555956678700361], 'roc_auc': [0.731023440525512, 0.6194845096291495, 0.9184258848466923, 0.7129555439380924, 0.707709148605732, 0.8691740890688259, 0.7340427927927928, 0.7273852370405526, 0.8217025699168555, 0.7920815767217974, 0.7626858710050559, 0.7065794220399484, 0.7537604072944859, 0.7668720804137471, 0.7964914141414141, 0.7336047979797979, 0.7517651794186827, 0.6952041211904336, 0.7897701178643755], 'f1': [0.43314574833326325, 0.322369464715765, 0.5437420555883619, 0.40187928962646147, 0.45135332349710733, 0.6332490538249501, 0.5501690988452299, 0.4425924646735228, 0.5792309396872741, 0.5902077463307961, 0.43619838672970107, 0.4326335089104598, 0.5029779048957131, 0.5538464723682114, 0.5985371587992937, 0.4657783765829742, 0.5066784520283877, 0.3651456527908968, 0.5374810584257007]}\n",
      "logistic4 evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3907563025210084, 0.5734265734265734, 0.4781021897810219, 0.4676258992805755, 0.6461538461538462, 0.5211267605633803, 0.5107142857142857, 0.5894736842105263, 0.5968992248062015, 0.48028673835125446, 0.5130890052356021, 0.5079365079365079, 0.5653846153846154, 0.6153846153846154, 0.5222222222222223, 0.5220588235294118, 0.45627376425855515, 0.5595667870036101], 'roc_auc': [0.7266977575133168, 0.6241282446047052, 0.9168318822094056, 0.7061028460741584, 0.6881860782342324, 0.8714116059379217, 0.7191905968468468, 0.7300474938037231, 0.8179169816074578, 0.7909163312412965, 0.7281611804532009, 0.7009486310473152, 0.7484676674182625, 0.7700106356356358, 0.7990760942760943, 0.7321731200897869, 0.7536794434175672, 0.6942568239200014, 0.7869614123389003], 'f1': [0.44410612173708436, 0.33267603716678484, 0.5446422955762932, 0.4062016954368709, 0.40541896273573585, 0.6275228453093156, 0.5197015500152419, 0.4559900087057407, 0.5705263157894737, 0.5888599918940551, 0.41069037518187973, 0.4277730725798173, 0.48366807040276427, 0.5448051723601024, 0.6160875594505545, 0.47213227513227507, 0.4894578606825618, 0.39551822846918216, 0.5423450384205539]}\n",
      "logistic5 evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3907563025210084, 0.5734265734265734, 0.48175182481751827, 0.4676258992805755, 0.6461538461538462, 0.5117370892018779, 0.5142857142857142, 0.5947368421052631, 0.5930232558139535, 0.48028673835125446, 0.5130890052356021, 0.503968253968254, 0.5653846153846154, 0.6153846153846154, 0.5259259259259259, 0.5257352941176471, 0.45627376425855515, 0.5631768953068592], 'roc_auc': [0.7262463739523737, 0.6251418037436189, 0.9163535658828749, 0.7054412636530732, 0.6869608072887137, 0.8715465587044534, 0.718120777027027, 0.7304322891947477, 0.8187311035525321, 0.790295025954399, 0.7176703130862724, 0.7001440628085366, 0.7480202311612337, 0.7704605647313981, 0.7999170033670033, 0.7316393097643098, 0.753564762971258, 0.694283910856643, 0.7865328723827923], 'f1': [0.44488840063734103, 0.3329958557383185, 0.5446422955762932, 0.4131090328467153, 0.40541896273573585, 0.6275228453093156, 0.509174538178966, 0.45883738615938746, 0.5784410775682927, 0.5848039223201543, 0.41069037518187973, 0.4277730725798173, 0.47841724641698674, 0.5448051723601024, 0.6160875594505545, 0.4750988177459053, 0.49335878938397426, 0.39551822846918216, 0.5473751354609928]}\n",
      "logistic6 evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikel\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'accuracy': [0.5154639175257731, 0.3907563025210084, 0.5734265734265734, 0.48175182481751827, 0.46402877697841727, 0.6461538461538462, 0.5117370892018779, 0.5107142857142857, 0.5947368421052631, 0.5852713178294574, 0.4767025089605735, 0.5130890052356021, 0.503968253968254, 0.5653846153846154, 0.6153846153846154, 0.5296296296296297, 0.5220588235294118, 0.4600760456273764, 0.5631768953068592], 'roc_auc': [0.7260836128221428, 0.6253511330794371, 0.9166554982500247, 0.7054592152607931, 0.6855043412599019, 0.871715249662618, 0.717341873123123, 0.730186745240732, 0.8188145628621819, 0.7907406700876876, 0.7194257355547679, 0.7001215159109897, 0.7476933052122378, 0.770508008008008, 0.7993957912457912, 0.7317810044893379, 0.7541500829746758, 0.6941994194946423, 0.7865835006821053], 'f1': [0.44488840063734103, 0.3329958557383185, 0.5446422955762932, 0.4131090328467153, 0.40105868435890046, 0.6275228453093156, 0.509174538178966, 0.4559900087057407, 0.5784410775682927, 0.5761592210292621, 0.40384587724601717, 0.4277730725798173, 0.47841724641698674, 0.5448051723601024, 0.6160875594505545, 0.48205454252604635, 0.4894578606825618, 0.4026139880610602, 0.5473751354609928]}\n",
      "logistic7 evaluated\n",
      "\n",
      "Rank=1, Name=logistic3, Accuracy=0.532, roc_auc=0.756, f1=0.493\n",
      "Rank=2, Name=logistic4, Accuracy=0.531, roc_auc=0.757, f1=0.492\n",
      "Rank=3, Name=logistic6, Accuracy=0.528, roc_auc=0.752, f1=0.489\n",
      "Rank=4, Name=logistic5, Accuracy=0.528, roc_auc=0.753, f1=0.488\n",
      "Rank=5, Name=logistic7, Accuracy=0.528, roc_auc=0.752, f1=0.488\n",
      "Rank=6, Name=logistic2, Accuracy=0.515, roc_auc=0.723, f1=0.477\n",
      "Rank=7, Name=logistic1, Accuracy=0.422, roc_auc=0.694, f1=0.321\n",
      "0.4215134772850933 ['logistic3', 'logistic4', 'logistic6', 'logistic5', 'logistic7', 'logistic2', 'logistic1']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate models\n",
    "results = evaluate_models(X_scaled_train, Y_train, models, subjects_train)\n",
    "# summarize results\n",
    "summarize_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we obtain that standardizing and normalizing the data the best three models are SVCL, SVMP and Logistic with mean estimated accuracies of 0.638, 0.614 and 0.602 respectively. Better results that only standardizing the data. Let's try to perform some dimensionality reduction (PCA) to see if we can improve the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
